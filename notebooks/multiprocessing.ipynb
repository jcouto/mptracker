{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joao/data/eyecam/181112_JC086_2P_JC/run00_gray\n",
      "72\n",
      "There are 18229 frames in 72 files\n",
      "\t - Processing 72 files.\n",
      "\t - Analysed 18229 frames in 5.9 s [3075 fps]\n"
     ]
    }
   ],
   "source": [
    "# multiprocess data from filename pool\n",
    "%gui qt\n",
    "from mptracker import MPTracker,TiffFileSequence\n",
    "from mptracker import ellipseToContour\n",
    "from json import load as jload\n",
    "\n",
    "filename = '/home/joao/data/eyecam/181112_JC086_2P_JC/run00_gray/20181112_run000_00000000.tif'\n",
    "parameterfile = '/home/joao/data/eyecam/181112_JC086_2P_JC/run00_gray/20181112_run000.json'\n",
    "\n",
    "seq = TiffFileSequence(filename)\n",
    "\n",
    "with open(parameterfile,'r') as fd:\n",
    "    trackerpar = jload(fd)\n",
    "\n",
    "from mptracker.parutils import par_process_tiff\n",
    "\n",
    "res = par_process_tiff(seq.filenames,trackerpar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "class play_mptracker_results(object):\n",
    "    paused = False\n",
    "    gaussBlurSize = 3\n",
    "    gaussBlurSigma = 2\n",
    "    clahe = cv2.createCLAHE(clipLimit=35.0, tileGridSize=(8,8))\n",
    "    def __init__(self,stack,results):\n",
    "        self.movie = stack\n",
    "        self.N = stack.nFrames\n",
    "        self.results = results\n",
    "        self.iFrame = 0\n",
    "        self.wname = 'mptracker results'\n",
    "        \n",
    "    def play(self):\n",
    "        cv2.namedWindow(self.wname)\n",
    "        cv2.createTrackbar('Frame number',self.wname,0,self.N-1,lambda x:x)\n",
    "        while True:\n",
    "            if not self.paused:\n",
    "                self.iFrame = np.mod(self.iFrame + 1,self.N)\n",
    "                cv2.setTrackbarPos('Frame number',self.wname,self.iFrame)\n",
    "            self.iFrame = cv2.getTrackbarPos('Frame number',self.wname)\n",
    "            self.setImage(self.iFrame)\n",
    "            k = cv2.waitKey(3)\n",
    "            if k == ord('q'):\n",
    "                cv2.destroyAllWindows()        \n",
    "                break\n",
    "            elif k == ord('s'):\n",
    "                self.paused = not self.paused\n",
    "        \n",
    "    def setImage(self,iFrame):\n",
    "    \n",
    "        img = self.movie.get(self.iFrame)\n",
    "        img = self.clahe.apply(img)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        cv2.putText(img, 'frame {0}'.format(self.iFrame), (50,50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1.0, (128, 128, 200), \n",
    "                        lineType=cv2.LINE_AA)\n",
    "        if not np.isnan(self.results[self.iFrame,1][0]):\n",
    "            xy = (int(res[self.iFrame,1][0]),int(res[self.iFrame,1][1]))\n",
    "            c = ellipseToContour([xy[1],xy[0]],\n",
    "                                 self.results[self.iFrame,3][0]/2.,\n",
    "                                 self.results[self.iFrame,3][1]/2.,\n",
    "                                 0)#res[self.iFrame,3][2]+90)\n",
    "            cv2.drawContours(img,[c],0,[0,0,255],1)\n",
    "\n",
    "            img = cv2.circle(img,xy , 2, [128,0,128], 1)\n",
    "        \n",
    "        cv2.imshow('mptracker results',img)\n",
    "    \n",
    "sbxplay = play_mptracker_results(seq,res)\n",
    "sbxplay.play()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-027df74d4a4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0msplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_mptracker_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0msplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;31m#splay.save('/home/joao/data/facecam/whisker_top_view/topview_example.avi')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-027df74d4a4a>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menhanceImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlastImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             cv2.putText(img, 'frame {0}'.format(self.iFrame), (50,50),\n",
      "\u001b[0;32m<ipython-input-38-027df74d4a4a>\u001b[0m in \u001b[0;36menhanceImage\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mellipse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarkeredgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarkersize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menhanceImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclahe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# With enhanced\n",
    "class play_mptracker_results(object):\n",
    "    gaussBlurSize = 3\n",
    "    gaussBlurSigma = 2\n",
    "    clahe = cv2.createCLAHE(clipLimit=35.0, tileGridSize=(8,8))\n",
    "    paused = False\n",
    "    def __init__(self,data,res):\n",
    "        self.data = data\n",
    "        self.res = res\n",
    "        self.N = data.nFrames\n",
    "        self.iFrame = 0\n",
    "        self.lastImg = self.enhanceImage(self.data.get(self.iFrame))\n",
    "        self.ellipse = np.vstack(res[:,3])\n",
    "        self.fig = plt.figure()\n",
    "        self.diamplt = plt.plot(self.ellipse[:,0])\n",
    "        self.marker = plt.plot(self.iFrame,self.ellipse[self.iFrame,0],'o',markeredgecolor='r',markersize = 10)\n",
    "    def enhanceImage(self,img):\n",
    "        return self.clahe.apply(img) \n",
    "    \n",
    "    def play(self):\n",
    "        while True:\n",
    "            img = self.enhanceImage(self.data.get(self.iFrame)) \n",
    "            self.lastImg = img.copy()\n",
    "            cv2.putText(img, 'frame {0}'.format(self.iFrame), (50,50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1.0, (255, 255, 255), \n",
    "                        lineType=cv2.LINE_AA)\n",
    "            if not np.isnan(res[self.iFrame,1][0]):\n",
    "                xy = (int(res[self.iFrame,1][0]),int(res[self.iFrame,1][1]))\n",
    "#                 img = getEllipseMask(img.shape,[xy[0],xy[1]],[res[self.iFrame,3][0]/2,\n",
    "#                                      res[self.iFrame,3][1]/2],[res[self.iFrame,3][2]])\n",
    "                c = ellipseToContour([xy[1],xy[0]],\n",
    "                                     res[self.iFrame,3][0]/2.,\n",
    "                                     res[self.iFrame,3][1]/2.,\n",
    "                                     0)#res[self.iFrame,3][2]+90)\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "                cv2.drawContours(img,[c],0,[0,0,255],1)\n",
    "            img = cv2.circle(img,xy , 2, 255, 1)\n",
    "            cv2.imshow('img',img)\n",
    "            self.marker[0].set_xdata(self.iFrame)\n",
    "            self.marker[0].set_ydata(self.ellipse[self.iFrame,0])\n",
    "            plt.draw()\n",
    "            plt.pause(0.01)\n",
    "            if not self.paused:\n",
    "                self.iFrame = np.mod(self.iFrame + 1,self.N)\n",
    "            k = cv2.waitKey(3)\n",
    "            if k == ord('q'):\n",
    "                break\n",
    "            elif k == ord('s'):\n",
    "                self.paused = not self.paused\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "splay = play_mptracker_results(seq,res)\n",
    "splay.play()\n",
    "#splay.save('/home/joao/data/facecam/whisker_top_view/topview_example.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import pylab as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "splay.marker.set_offsets?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa2b5aef668>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot overlay\n",
    "import cv2\n",
    "import numpy as np\n",
    "class playStack(object):\n",
    "    gaussBlurSize = 3\n",
    "    gaussBlurSigma = 2\n",
    "    clahe = cv2.createCLAHE(clipLimit=35.0, tileGridSize=(8,8))\n",
    "    paused = False\n",
    "    def __init__(self,data,res):\n",
    "        self.data = data\n",
    "        self.res = res\n",
    "        self.N = data.nFrames\n",
    "        self.iFrame = 0\n",
    "        self.lastImg = self.enhanceImage(self.data.get(self.iFrame))\n",
    "    def enhanceImage(self,img):\n",
    "        return self.clahe.apply(cv2.GaussianBlur(img,\n",
    "                                                 (self.gaussBlurSize,\n",
    "                                                  self.gaussBlurSize),\n",
    "                                                 self.gaussBlurSigma))   \n",
    "    def play(self):\n",
    "        while True:\n",
    "            img = self.enhanceImage(self.data.get(self.iFrame)) \n",
    "            self.lastImg = img.copy()\n",
    "            cv2.putText(img, 'frame {0}'.format(self.iFrame), (50,50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1.0, (255, 255, 255), \n",
    "                        lineType=cv2.LINE_AA)\n",
    "            if not np.isnan(res[self.iFrame,1][0]):\n",
    "                xy = (int(res[self.iFrame,1][0]),int(res[self.iFrame,1][1]))\n",
    "            \n",
    "                c = ellipseToContour([xy[1],xy[0]],\n",
    "                                     res[self.iFrame,3][0]/2.,\n",
    "                                     res[self.iFrame,3][1]/2.,\n",
    "                                     0)#res[self.iFrame,3][2]+90)\n",
    "\n",
    "                cv2.drawContours(img,[c],0,255,1)\n",
    "            img = cv2.circle(img,xy , 2, 255, 1)\n",
    "            cv2.imshow('img',img)\n",
    "            if not self.paused:\n",
    "                self.iFrame = np.mod(self.iFrame + 1,self.N)\n",
    "            k = cv2.waitKey(3)\n",
    "            if k == ord('q'):\n",
    "                break\n",
    "            elif k == ord('s'):\n",
    "                self.paused = not self.paused\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "splay = playStack(seq,res)\n",
    "splay.play()\n",
    "#splay.save('/home/joao/data/facecam/whisker_top_view/topview_example.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f22e4211438>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mptracker import ellipseToContour\n",
    "import pylab as plt\n",
    "%matplotlib qt\n",
    "c = ellipseToContour(res[0,1],res[0,3][0]/2,res[0,3][1]/2,res[0,3][2])\n",
    "plt.imshow(seq.get(0)**0.5,cmap = 'gray')\n",
    "plt.plot(c[:,0,1],c[:,0,0],'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-3129a9323000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m az,el,theta = convertPixelToEyeCoords(np.hstack(res[1]),\n\u001b[1;32m      3\u001b[0m                                       \u001b[0;34m(\u001b[0m\u001b[0mtrackerpar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrackerpar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                       np.hstack(res[0]))\n\u001b[0m",
      "\u001b[0;32m~/lib/mptracker/mptracker/utils.py\u001b[0m in \u001b[0;36mconvertPixelToEyeCoords\u001b[0;34m(pupilPix, eyeCorners, crPix, eyeDiameterEstimate)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Correct for movement of the entire eye.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcrPix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mpPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mpPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mcFactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeConversionFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meyeCorners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "from mptracker import convertPixelToEyeCoords\n",
    "az,el,theta = convertPixelToEyeCoords(np.hstack(res[1]),\n",
    "                                      (trackerpar['points'][0],trackerpar['points'][2]),\n",
    "                                      np.hstack(res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mptracker import getEllipseMask\n",
    "MPTracker.getAugmented??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
