{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joao/data/eyecam/181112_JC086_2P_JC/run00_gray\n",
      "72\n",
      "There are 18229 frames in 72 files\n",
      "Analysed 18229 frames in 6.704983711242676 s [2718.7239798113555 fps]\n"
     ]
    }
   ],
   "source": [
    "# multiprocess data from filename pool\n",
    "\n",
    "from mptracker import MPTracker,TiffFileSequence\n",
    "import cv2\n",
    "from tifffile import imread\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "from json import load as jload\n",
    "import  numpy as np\n",
    "filename = '/home/joao/data/eyecam/181112_JC086_2P_JC/run00_gray/20181112_run000_00000000.tif'\n",
    "parameterfile = '/home/joao/data/eyecam/181112_JC086_2P_JC/run00_gray/20181112_run000.json'\n",
    "seq = TiffFileSequence(filename)\n",
    "\n",
    "with open(parameterfile,'r') as fd:\n",
    "    trackerpar = jload(fd)\n",
    "mptracker = MPTracker(trackerpar)\n",
    "\n",
    "def process_tiff(fname,parameters):\n",
    "    cv2.setNumThreads(0)\n",
    "    tracker = MPTracker(parameters)\n",
    "    dat = imread(fname)\n",
    "    if len(dat.shape) < 3:\n",
    "        dat = [dat]\n",
    "    res = []\n",
    "    for frame in dat:\n",
    "        res.append(tracker.apply(frame))\n",
    "    del tracker\n",
    "    return res\n",
    "\n",
    "from multiprocess import Pool\n",
    "from functools import partial\n",
    "import time\n",
    "nprocesses = 12\n",
    "ts = time.time()\n",
    "with Pool(nprocesses) as pool:\n",
    "    res = pool.map(partial(process_tiff,parameters = trackerpar),seq.filenames)\n",
    "    res = np.vstack(res)\n",
    "    \n",
    "toc = time.time() - ts\n",
    "print('Analysed {0} frames in {1} s [{2} fps]'.format(seq.nFrames,toc,seq.nFrames/toc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105.11105346679688, 119.55891418457031, 32.00214385986328)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With enhanced\n",
    "class playStack(object):\n",
    "    gaussBlurSize = 3\n",
    "    gaussBlurSigma = 2\n",
    "    clahe = cv2.createCLAHE(clipLimit=35.0, tileGridSize=(8,8))\n",
    "    paused = False\n",
    "    def __init__(self,data,res):\n",
    "        self.data = data\n",
    "        self.res = res\n",
    "        self.N = data.nFrames\n",
    "        self.iFrame = 0\n",
    "        self.lastImg = self.enhanceImage(self.data.get(self.iFrame))\n",
    "    def enhanceImage(self,img):\n",
    "        return self.clahe.apply(cv2.GaussianBlur(img,\n",
    "                                                 (self.gaussBlurSize,\n",
    "                                                  self.gaussBlurSize),\n",
    "                                                 self.gaussBlurSigma))   \n",
    "    def play(self):\n",
    "        while True:\n",
    "            img = self.enhanceImage(self.data.get(self.iFrame)) \n",
    "            self.lastImg = img.copy()\n",
    "            cv2.putText(img, 'frame {0}'.format(self.iFrame), (50,50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1.0, (255, 255, 255), \n",
    "                        lineType=cv2.LINE_AA)\n",
    "            if not np.isnan(res[self.iFrame,1][0]):\n",
    "                xy = (int(res[self.iFrame,1][0]),int(res[self.iFrame,1][1]))\n",
    "                img = getEllipseMask(img.shape,[xy[0],xy[1]],[res[self.iFrame,3][0]/2,\n",
    "                                     res[self.iFrame,3][1]/2],[res[self.iFrame,3][2]])\n",
    "                c = ellipseToContour([xy[1],xy[0]],\n",
    "                                     res[self.iFrame,3][0]/2.,\n",
    "                                     res[self.iFrame,3][1]/2.,\n",
    "                                     0)#res[self.iFrame,3][2]+90)\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "                cv2.drawContours(img,[c],0,[0,0,255],1)\n",
    "            img = cv2.circle(img,xy , 2, 255, 1)\n",
    "            cv2.imshow('img',img)\n",
    "            if not self.paused:\n",
    "                self.iFrame = np.mod(self.iFrame + 1,self.N)\n",
    "            k = cv2.waitKey(3)\n",
    "            if k == ord('q'):\n",
    "                break\n",
    "            elif k == ord('s'):\n",
    "                self.paused = not self.paused\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "splay = playStack(seq,res)\n",
    "splay.play()\n",
    "#splay.save('/home/joao/data/facecam/whisker_top_view/topview_example.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot overlay\n",
    "class playStack(object):\n",
    "    gaussBlurSize = 3\n",
    "    gaussBlurSigma = 2\n",
    "    clahe = cv2.createCLAHE(clipLimit=35.0, tileGridSize=(8,8))\n",
    "    paused = False\n",
    "    def __init__(self,data,res):\n",
    "        self.data = data\n",
    "        self.res = res\n",
    "        self.N = data.nFrames\n",
    "        self.iFrame = 0\n",
    "        self.lastImg = self.enhanceImage(self.data.get(self.iFrame))\n",
    "    def enhanceImage(self,img):\n",
    "        return self.clahe.apply(cv2.GaussianBlur(img,\n",
    "                                                 (self.gaussBlurSize,\n",
    "                                                  self.gaussBlurSize),\n",
    "                                                 self.gaussBlurSigma))   \n",
    "    def play(self):\n",
    "        while True:\n",
    "            img = self.enhanceImage(self.data.get(self.iFrame)) \n",
    "            self.lastImg = img.copy()\n",
    "            cv2.putText(img, 'frame {0}'.format(self.iFrame), (50,50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1.0, (255, 255, 255), \n",
    "                        lineType=cv2.LINE_AA)\n",
    "            if not np.isnan(res[self.iFrame,1][0]):\n",
    "                xy = (int(res[self.iFrame,1][0]),int(res[self.iFrame,1][1]))\n",
    "            \n",
    "                c = ellipseToContour([xy[1],xy[0]],\n",
    "                                     res[self.iFrame,3][0]/2.,\n",
    "                                     res[self.iFrame,3][1]/2.,\n",
    "                                     0)#res[self.iFrame,3][2]+90)\n",
    "\n",
    "                cv2.drawContours(img,[c],0,255,1)\n",
    "            img = cv2.circle(img,xy , 2, 255, 1)\n",
    "            cv2.imshow('img',img)\n",
    "            if not self.paused:\n",
    "                self.iFrame = np.mod(self.iFrame + 1,self.N)\n",
    "            k = cv2.waitKey(3)\n",
    "            if k == ord('q'):\n",
    "                break\n",
    "            elif k == ord('s'):\n",
    "                self.paused = not self.paused\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "splay = playStack(seq,res)\n",
    "splay.play()\n",
    "#splay.save('/home/joao/data/facecam/whisker_top_view/topview_example.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc15da02208>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mptracker import ellipseToContour\n",
    "import pylab as plt\n",
    "%matplotlib qt\n",
    "c = ellipseToContour(res[0,1],res[0,3][0]/2,res[0,3][1]/2,res[0,3][2])\n",
    "plt.imshow(seq.get(0)**0.5,cmap = 'gray')\n",
    "plt.plot(c[:,0,1],c[:,0,0],'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-3129a9323000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m az,el,theta = convertPixelToEyeCoords(np.hstack(res[1]),\n\u001b[1;32m      3\u001b[0m                                       \u001b[0;34m(\u001b[0m\u001b[0mtrackerpar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrackerpar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                       np.hstack(res[0]))\n\u001b[0m",
      "\u001b[0;32m~/lib/mptracker/mptracker/utils.py\u001b[0m in \u001b[0;36mconvertPixelToEyeCoords\u001b[0;34m(pupilPix, eyeCorners, crPix, eyeDiameterEstimate)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Correct for movement of the entire eye.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcrPix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mpPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mpPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrPix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mcFactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeConversionFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meyeCorners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "from mptracker import convertPixelToEyeCoords\n",
    "az,el,theta = convertPixelToEyeCoords(np.hstack(res[1]),\n",
    "                                      (trackerpar['points'][0],trackerpar['points'][2]),\n",
    "                                      np.hstack(res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mptracker import getEllipseMask\n",
    "MPTracker.getAugmented??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
